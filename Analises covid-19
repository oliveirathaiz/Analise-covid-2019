Análises COVID-19

Vamos analisar as séries temporais sobre a contaminação do vírus COVID-19 pelo mundo.
In [2]:
import pandas as pd
import numpy as np
from datetime import datetime #Mexer com datas
import plotly.express as px
import plotly.graph_objects as go
Ao importar os dados é importante já dizer no comando pd.read_csv quais são as colunas que serão "parseadas" como datas. O pandas possui métodos robustos para trabalhar com esse tipo de informação.
In [3]:
#Os dados estão disponíveis também no site do kaggle: https://www.kaggle.com/datasets/sudalairajkumar/novel-corona-virus-2019-dataset
url = 'https://github.com/ANACAPELETTI/DIO/blob/main/Bootcamp%20Gera%C3%A7%C3%A3o%20Tech%20Unimed-BH%20-%20Ci%C3%AAncia%20de%20Dados/projeto_eda_covid-master/covid_19_data.csv?raw=true'
df = pd.read_csv(url, parse_dates=['ObservationDate', 'Last Update'])
df
Out[3]:

SNo
ObservationDate
Province/State
Country/Region
Last Update
Confirmed
Deaths
Recovered
0
1
2020-01-22
Anhui
Mainland China
2020-01-22 17:00:00
1.0
0.0
0.0
1
2
2020-01-22
Beijing
Mainland China
2020-01-22 17:00:00
14.0
0.0
0.0
2
3
2020-01-22
Chongqing
Mainland China
2020-01-22 17:00:00
6.0
0.0
0.0
3
4
2020-01-22
Fujian
Mainland China
2020-01-22 17:00:00
1.0
0.0
0.0
4
5
2020-01-22
Gansu
Mainland China
2020-01-22 17:00:00
0.0
0.0
0.0
...
...
...
...
...
...
...
...
...
26708
26709
2020-05-19
Wyoming
US
2020-05-20 02:32:19
776.0
10.0
0.0
26709
26710
2020-05-19
Xinjiang
Mainland China
2020-05-20 02:32:19
76.0
3.0
73.0
26710
26711
2020-05-19
Yukon
Canada
2020-05-20 02:32:19
11.0
0.0
11.0
26711
26712
2020-05-19
Yunnan
Mainland China
2020-05-20 02:32:19
185.0
2.0
183.0
26712
26713
2020-05-19
Zhejiang
Mainland China
2020-05-20 02:32:19
1268.0
1.0
1267.0
26713 rows × 8 columns
In [4]:
df.dtypes #Verificando os tipos de cada coluna
Out[4]:
SNo                         int64
ObservationDate    datetime64[ns]
Province/State             object
Country/Region             object
Last Update        datetime64[ns]
Confirmed                 float64
Deaths                    float64
Recovered                 float64
dtype: object
É bom padronizar o nome das colunas, de forma que elas tenham letras maiúsculas e nem caracteres especiais. Para corrigir os nomes da nossa base vamos utilizar uma função utilizando a biblioteca re.
In [5]:
import re
def corrige_colunas(col_name):
    return re.sub(r"[/| ]", "", col_name).lower() #coloca todas as letras em minúsculo e troca o espaço e/ou a barra (/) por nada, unindo as palavras 
In [6]:
df.columns = [corrige_colunas(col) for col in df.columns]
In [7]:
df
Out[7]:

sno
observationdate
provincestate
countryregion
lastupdate
confirmed
deaths
recovered
0
1
2020-01-22
Anhui
Mainland China
2020-01-22 17:00:00
1.0
0.0
0.0
1
2
2020-01-22
Beijing
Mainland China
2020-01-22 17:00:00
14.0
0.0
0.0
2
3
2020-01-22
Chongqing
Mainland China
2020-01-22 17:00:00
6.0
0.0
0.0
3
4
2020-01-22
Fujian
Mainland China
2020-01-22 17:00:00
1.0
0.0
0.0
4
5
2020-01-22
Gansu
Mainland China
2020-01-22 17:00:00
0.0
0.0
0.0
...
...
...
...
...
...
...
...
...
26708
26709
2020-05-19
Wyoming
US
2020-05-20 02:32:19
776.0
10.0
0.0
26709
26710
2020-05-19
Xinjiang
Mainland China
2020-05-20 02:32:19
76.0
3.0
73.0
26710
26711
2020-05-19
Yukon
Canada
2020-05-20 02:32:19
11.0
0.0
11.0
26711
26712
2020-05-19
Yunnan
Mainland China
2020-05-20 02:32:19
185.0
2.0
183.0
26712
26713
2020-05-19
Zhejiang
Mainland China
2020-05-20 02:32:19
1268.0
1.0
1267.0
26713 rows × 8 columns
Análises
Agora vamos começar a investigar as variáveis que temos à disposição. Sabemos que trata-se de séries temporais que estão divididas por estado. Para fazer qualquer análise, portanto, precisamos dividir os nossos dados desse "grão".
Então vamos verificar primeiro quantos estados temos informações para o Brasil. Neste caso, já havia verificado a base de dados previamente mas, uma boa forma de verificar os Países presentes no DF seria utilizando: df.countryregion.unique().
In [8]:
df.loc[df.countryregion == 'Brazil']
Out[8]:

sno
observationdate
provincestate
countryregion
lastupdate
confirmed
deaths
recovered
82
83
2020-01-23
NaN
Brazil
2020-01-23 17:00:00
0.0
0.0
0.0
2455
2456
2020-02-26
NaN
Brazil
2020-02-26 23:53:02
1.0
0.0
0.0
2559
2560
2020-02-27
NaN
Brazil
2020-02-26 23:53:02
1.0
0.0
0.0
2668
2669
2020-02-28
NaN
Brazil
2020-02-26 23:53:02
1.0
0.0
0.0
2776
2777
2020-02-29
NaN
Brazil
2020-02-29 21:03:05
2.0
0.0
0.0
...
...
...
...
...
...
...
...
...
24850
24851
2020-05-15
NaN
Brazil
2020-05-16 02:32:19
220291.0
14962.0
84970.0
25227
25228
2020-05-16
NaN
Brazil
2020-05-17 02:32:32
233511.0
15662.0
89672.0
25604
25605
2020-05-17
NaN
Brazil
2020-05-18 02:32:21
241080.0
16118.0
94122.0
25981
25982
2020-05-18
NaN
Brazil
2020-05-19 02:32:18
255368.0
16853.0
100459.0
26358
26359
2020-05-19
NaN
Brazil
2020-05-20 02:32:19
271885.0
17983.0
106794.0
85 rows × 8 columns
No caso do Brasil, não possuímos informação a nível de estado, apenas a nível do país. Desta forma, vamos verificar como está o comportamento dos casos confirmados no Brasil desde o primeiro caso confirmado, 26 de fevereiro.
Casos confirmados
In [10]:
brasil = df.loc[(df.countryregion == 'Brazil') & (df.confirmed > 0)]
In [11]:
#Gráfico da evolução de casos confirmados
px.line(brasil, 'observationdate', 'confirmed', 
        labels={'observationdate':'Data', 'confirmed':'Número de casos confirmados'},
       title='Casos confirmados no Brasil')

Número de novos casos por dia
In [12]:
# Vamos implementar uma função para fazer a contagem de novos casos
brasil['novoscasos'] = list(map(
    lambda x: 0 if (x==0) else brasil['confirmed'].iloc[x] - brasil['confirmed'].iloc[x-1], #A partir do segundo dia, será sempre subtraído o número de casos do dia atual menos o do dia anterior
    np.arange(brasil.shape[0]) #A função lambda acima será aplicada nas linhas do nosso DF "brasil"
))
C:\Users\ana.almeida\AppData\Local\Temp\ipykernel_6192\719604648.py:2: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

In [13]:
# Visualizando
px.line(brasil, x='observationdate', y='novoscasos', title='Novos casos por dia',
       labels={'observationdate': 'Data', 'novoscasos': 'Novos casos'})

Óbitos
In [14]:
fig = go.Figure()

fig.add_trace(
    go.Scatter(x=brasil.observationdate, y=brasil.deaths, name='Mortes', mode='lines+markers',
              line=dict(color='red'))
)

#Editando o layout
fig.update_layout(title='Mortes por COVID-19 no Brasil',
                   xaxis_title='Data',
                   yaxis_title='Número de mortes')
fig.show()

Taxa de crescimento
Calculando a taxa de crescimento do COVID desde o primeiro caso.
taxa_crescimento = (presente/passado)**(1/n) -1
In [15]:
def taxa_crescimento(data, variable, data_inicio=None, data_fim=None):
    if data_inicio == None:
        data_inicio = data.observationdate.loc[data[variable] > 0].min() #Se data_inicio for 'None', define como a primeira data disponível no dataset
    else:
        data_inicio = pd.to_datetime(data_inicio)
        
    if data_fim == None:
        data_fim = data.observationdate.iloc[-1] #Se data_inicio for 'None', define como a última data disponível no dataset
    else:
        data_fim = pd.to_datetime(data_fim)
    
    #Definindo os valores de presente e passado
    passado = data.loc[data.observationdate == data_inicio, variable].values[0]
    presente = data.loc[data.observationdate == data_fim, variable].values[0]
    
    #Definindo o número de pontos no tempo q vamos avaliar
    n = (data_fim - data_inicio).days
    
    #Calculando a taxa
    taxa = (presente/passado)**(1/n) - 1

    return taxa*100
In [16]:
#Calculando a taxa de crescimento médio do COVID no Brasil em todo o período
cresc_medio = taxa_crescimento(brasil, 'confirmed')
print(f"O crescimento médio do COVID-19 no Brasil no período avaliado foi de {cresc_medio.round(2)}%.")
O crescimento médio do COVID-19 no Brasil no período avaliado foi de 16.27%.
Taxa de crescimento diária
Agora, vamos observar o comportamento da taxa de crescimento no tempo. Para isso, vamos definir uma função para calcular a taxa de crescimento diária.
In [17]:
def taxa_crescimento_diaria(data, variable, data_inicio=None):
    if data_inicio == None:
        data_inicio = data.observationdate.loc[data[variable] > 0].min()
    else:
        data_inicio = pd.to_datetime(data_inicio)
        
    data_fim = data.observationdate.max()
    n = (data_fim - data_inicio).days #Define o número de pontos no tempo que vamos avaliar
    
    #Taxa calculada de um dia para o outro
    taxas = list(map(
        lambda x: (data[variable].iloc[x] - data[variable].iloc[x-1]) / data[variable].iloc[x-1],
        range(1,n+1)
    ))
    return np.array(taxas)*100
In [18]:
tx_dia = taxa_crescimento_diaria(brasil, 'confirmed')
In [19]:
tx_dia
Out[19]:
array([  0.        ,   0.        , 100.        ,   0.        ,
         0.        ,   0.        , 100.        ,   0.        ,
       225.        ,   0.        ,  53.84615385,  25.        ,
        24.        ,  22.58064516,  36.84210526, 190.38461538,
         0.        ,   7.28476821,  23.45679012,  60.5       ,
        15.88785047,  66.93548387,  27.69726248,  28.75157629,
        51.4201763 ,  24.45019405,  16.78794179,  13.66266133,
        16.87548943,  14.47236181,  14.25226807,   9.01639344,
         7.58928571,  24.8525879 ,  19.57320273,  17.67115272,
        12.58080557,  14.39929329,   7.43243243,   9.26325247,
        15.40169394,  15.22017956,  11.88620903,   8.54521335,
         5.54537122,   7.06807546,   5.57858688,   7.81903542,
        12.10513815,   7.4329096 ,  10.70501233,   8.83557983,
         5.44492335,   5.4043566 ,   5.73350023,   6.21648599,
         9.35157462,   8.00823407,   9.77184834,   6.36504619,
         6.88748019,   8.58316283,   8.80726429,   9.41456987,
         5.75200431,   5.31224919,   4.86714727,   6.67216624,
         6.29257964,   9.66263912,   7.23633807,   8.19087742,
         6.24055441,   4.25346499,   4.23788714,   5.08272698,
         6.69027125,   6.85190152,   8.42960156,   6.00115302,
         3.24138906,   5.92666335,   6.4679208 ])
In [20]:
primeiro_dia = brasil.observationdate.loc[brasil.confirmed > 0].min()
px.line(x=pd.date_range(primeiro_dia, brasil.observationdate.max())[1:], 
        y=tx_dia, title='Taxa de crescimento de casos confirmados no Brasil',
       labels={'y':'Taxa de crescimento', 'x':'Data'})

Predições
Vamos construir um modelo de séries temporais para prever os novos casos. Antes analisemos a série temporal.
In [21]:
from statsmodels.tsa.seasonal import seasonal_decompose
import matplotlib.pyplot as plt
In [22]:
novoscasos = brasil.novoscasos
novoscasos.index = brasil.observationdate

res = seasonal_decompose(novoscasos)

fig, (ax1,ax2,ax3, ax4) = plt.subplots(4, 1,figsize=(10,8)) #Plotar 4 gráficos em uma coluna
ax1.plot(res.observed)
ax2.plot(res.trend)
ax3.plot(res.seasonal)
ax4.scatter(novoscasos.index, res.resid) #Resid = ruído
ax4.axhline(0, linestyle='dashed', c='black')
plt.show()

Decompondo a série de confirmados
In [23]:
confirmados = brasil.confirmed
confirmados.index = brasil.observationdate
In [24]:
res2 = seasonal_decompose(confirmados)

fig, (ax1,ax2,ax3, ax4) = plt.subplots(4, 1,figsize=(10,8))
ax1.plot(res2.observed)
ax2.plot(res2.trend)
ax3.plot(res2.seasonal)
ax4.scatter(confirmados.index, res2.resid)
ax4.axhline(0, linestyle='dashed', c='black')
plt.show()

Predizendo o número de casos confirmados com um AUTO-ARIMA
In [25]:
#Método ARIMA = média móvel integrada auto regressiva 
!pip install pmdarima
Requirement already satisfied: pmdarima in c:\users\ana.almeida\anaconda3\lib\site-packages (2.0.1)
Requirement already satisfied: numpy>=1.21 in c:\users\ana.almeida\anaconda3\lib\site-packages (from pmdarima) (1.21.5)
Requirement already satisfied: scikit-learn>=0.22 in c:\users\ana.almeida\anaconda3\lib\site-packages (from pmdarima) (1.0.2)
Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in c:\users\ana.almeida\anaconda3\lib\site-packages (from pmdarima) (61.2.0)
Requirement already satisfied: scipy>=1.3.2 in c:\users\ana.almeida\anaconda3\lib\site-packages (from pmdarima) (1.7.3)
Requirement already satisfied: joblib>=0.11 in c:\users\ana.almeida\anaconda3\lib\site-packages (from pmdarima) (1.1.0)
Requirement already satisfied: statsmodels>=0.13.2 in c:\users\ana.almeida\anaconda3\lib\site-packages (from pmdarima) (0.13.2)
Requirement already satisfied: pandas>=0.19 in c:\users\ana.almeida\anaconda3\lib\site-packages (from pmdarima) (1.4.2)
Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in c:\users\ana.almeida\anaconda3\lib\site-packages (from pmdarima) (0.29.28)
Requirement already satisfied: urllib3 in c:\users\ana.almeida\anaconda3\lib\site-packages (from pmdarima) (1.26.9)
Requirement already satisfied: python-dateutil>=2.8.1 in c:\users\ana.almeida\anaconda3\lib\site-packages (from pandas>=0.19->pmdarima) (2.8.2)
Requirement already satisfied: pytz>=2020.1 in c:\users\ana.almeida\anaconda3\lib\site-packages (from pandas>=0.19->pmdarima) (2021.3)
Requirement already satisfied: six>=1.5 in c:\users\ana.almeida\anaconda3\lib\site-packages (from python-dateutil>=2.8.1->pandas>=0.19->pmdarima) (1.16.0)
Requirement already satisfied: threadpoolctl>=2.0.0 in c:\users\ana.almeida\anaconda3\lib\site-packages (from scikit-learn>=0.22->pmdarima) (2.2.0)
Requirement already satisfied: patsy>=0.5.2 in c:\users\ana.almeida\anaconda3\lib\site-packages (from statsmodels>=0.13.2->pmdarima) (0.5.2)
Requirement already satisfied: packaging>=21.3 in c:\users\ana.almeida\anaconda3\lib\site-packages (from statsmodels>=0.13.2->pmdarima) (21.3)
Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\users\ana.almeida\anaconda3\lib\site-packages (from packaging>=21.3->statsmodels>=0.13.2->pmdarima) (3.0.4)
In [26]:
from pmdarima.arima import auto_arima
In [27]:
modelo = auto_arima(confirmados)
In [28]:
pd.date_range('2020-05-01', '2020-05-19')
Out[28]:
DatetimeIndex(['2020-05-01', '2020-05-02', '2020-05-03', '2020-05-04',
               '2020-05-05', '2020-05-06', '2020-05-07', '2020-05-08',
               '2020-05-09', '2020-05-10', '2020-05-11', '2020-05-12',
               '2020-05-13', '2020-05-14', '2020-05-15', '2020-05-16',
               '2020-05-17', '2020-05-18', '2020-05-19'],
              dtype='datetime64[ns]', freq='D')
In [29]:
fig = go.Figure(go.Scatter(
    x=confirmados.index, y=confirmados, name='Observed'
))

fig.add_trace(go.Scatter(x=confirmados.index, y = modelo.predict_in_sample(), name='Predicted'))

fig.add_trace(go.Scatter(x=pd.date_range('2020-05-20', '2020-06-20'), y=modelo.predict(31), name='Forecast'))

fig.update_layout(title='Previsão de casos confirmados para os próximos 30 dias',
                 yaxis_title='Casos confirmados', xaxis_title='Data')
fig.show()

Modelo de crescimento
Forecasting com Facebook Prophet
É possível instalar o fbprophet utilizando os seguintes comandos no terminal do Anaconda: conda config --add channels conda-forge - a instalação do fbprophet partir do canal conda-forge pode ser obtida adicionando conda-forge aos seus canais;
Uma vez que o conda-forgecanal foi habilitado, fbprophetpode ser instalado com: conda install fbprophet. Também é possível instalar pelo comando abaixo (!conda install -c conda-forge fbprophet -y).
Para mais detalhes acesse o link abaixo e verifique a documentação oficial:
    • https://github.com/conda-forge/fbprophet-feedstock/blob/main/README.md
In [31]:
!conda install -c conda-forge fbprophet -y
^C
In [33]:
from fbprophet import Prophet
In [40]:
#Preparando os dados -> pré-processamentos
train = confirmados.reset_index()[:-5] #Do início até os últimos, menos 5
test = confirmados.reset_index()[-5:] #Os cinco últimos

#Renomeando colunas, pois, a biblioteca pede isso
train.rename(columns={"observationdate":"ds","confirmed":"y"},inplace=True)
test.rename(columns={"observationdate":"ds","confirmed":"y"},inplace=True)
test = test.set_index("ds")
test = test['y']

#Definindo o modelo de crescimento
profeta = Prophet(growth="logistic", changepoints=['2020-03-21', '2020-03-30', '2020-04-25', '2020-05-03', '2020-05-10']) #Logistic = sigmoid

pop = 215211471 #População do Brasil segundo o IBGE -> https://www.ibge.gov.br/apps/populacao/projecao/box_popclock.php
train['cap'] = pop

#Treinando o modelo
profeta.fit(train)

#Construindo as previsões
future_dates = profeta.make_future_dataframe(periods=200)
future_dates['cap'] = pop
forecast =  profeta.predict(future_dates)
INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.
INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.
In [41]:
#Mostrando a predição
fig = go.Figure()
fig.add_trace(go.Scatter(x=forecast.ds, y=forecast.yhat, name='Predição'))
fig.add_trace(go.Scatter(x=test.index, y=test, name='Observados - Teste'))
fig.add_trace(go.Scatter(x=train.ds, y=train.y, name='Observados - Treino'))
fig.update_layout(title='Predições de casos confirmados no Brasil')
fig.show()

